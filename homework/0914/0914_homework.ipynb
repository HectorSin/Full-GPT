{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b6c5b5",
   "metadata": {},
   "source": [
    "Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
    "\n",
    "체인을 수동으로 구현해야 합니다.\n",
    "\n",
    "체인에 ConversationBufferMemory를 부여합니다.\n",
    "\n",
    "이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
    "\n",
    "체인에 다음 질문을 합니다:\n",
    "\n",
    "Aaronson 은 유죄인가요?\n",
    "\n",
    "그가 테이블에 어떤 메시지를 썼나요?\n",
    "\n",
    "Julia 는 누구인가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c73924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "from get_env import get_env\n",
    "import requests\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# API 키 설정\n",
    "api_key = get_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b77d6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서가 34개의 청크로 분할되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 문서 로딩 및 분할\n",
    "loader = TextLoader(\"../../files/chapter_three.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "docs = splitter.split_documents(documents)\n",
    "print(f\"문서가 {len(docs)}개의 청크로 분할되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96d2d5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터스토어 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 및 벡터스토어 설정\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"벡터스토어 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03896b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 및 메모리 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# LLM 및 메모리 설정\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"당신은 도움이 되는 어시스턴트입니다. 주어진 컨텍스트를 사용하여 질문에 답하세요. \n",
    "    답을 모르면 모른다고 말하고, 답을 만들어내지 마세요.\n",
    "    \n",
    "    컨텍스트: {context}\n",
    "    \n",
    "    대화 기록: {chat_history}\"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "print(\"LLM 및 메모리 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5ade7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stuff Documents 체인 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# Stuff Documents 체인 수동 구현\n",
    "class StuffDocumentsChain:\n",
    "    def __init__(self, retriever, prompt, llm, memory):\n",
    "        self.retriever = retriever\n",
    "        self.prompt = prompt\n",
    "        self.llm = llm\n",
    "        self.memory = memory\n",
    "    \n",
    "    def _get_relevant_documents(self, question: str) -> str:\n",
    "        \"\"\"관련 문서들을 검색하고 결합\"\"\"\n",
    "        docs = self.retriever.get_relevant_documents(question)\n",
    "        return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    def invoke(self, question: str) -> str:\n",
    "        \"\"\"질문에 대한 답변 생성\"\"\"\n",
    "        # 관련 문서 검색\n",
    "        context = self._get_relevant_documents(question)\n",
    "        \n",
    "        # 메모리에서 대화 기록 가져오기\n",
    "        chat_history = self.memory.chat_memory.messages\n",
    "        \n",
    "        # 프롬프트에 입력값 설정\n",
    "        formatted_prompt = self.prompt.format(\n",
    "            context=context,\n",
    "            question=question,\n",
    "            chat_history=chat_history\n",
    "        )\n",
    "        \n",
    "        # LLM으로 답변 생성\n",
    "        response = self.llm.invoke(formatted_prompt)\n",
    "        \n",
    "        # 메모리에 대화 저장\n",
    "        self.memory.chat_memory.add_user_message(question)\n",
    "        self.memory.chat_memory.add_ai_message(response.content)\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "# 체인 생성\n",
    "chain = StuffDocumentsChain(retriever, prompt, llm, memory)\n",
    "print(\"Stuff Documents 체인 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fe705e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 질문 1: Aaronson은 유죄인가요? ===\n",
      "System: 네, Jones, Aaronson 및 Rutherford는 자신들에게 적용된 범죄로 유죄 판결을 받았습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 질문 1: Aaronson은 유죄인가요?\n",
    "print(\"=== 질문 1: Aaronson은 유죄인가요? ===\")\n",
    "answer1 = chain.invoke(\"Aaronson은 유죄인가요?\")\n",
    "print(answer1)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1cbbb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 질문 2: 그가 테이블에 어떤 메시지를 썼나요? ===\n",
      "System: 책에서 언급된 내용에는 Aaronson이 테이블에 어떤 메시지를 썼는지에 대한 구체적인 정보가 포함되어 있지 않습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 질문 2: 그가 테이블에 어떤 메시지를 썼나요?\n",
    "print(\"=== 질문 2: 그가 테이블에 어떤 메시지를 썼나요? ===\")\n",
    "answer2 = chain.invoke(\"그가 테이블에 어떤 메시지를 썼나요?\")\n",
    "print(answer2)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7f90fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 질문 3: Julia는 누구인가요? ===\n",
      "System: Julia는 책에서 언급된 다른 주요 캐릭터 중 하나로, 윈스턴과 함께 이야기의 중심에 있는 여성입니다. 그녀는 윈스턴의 사랑이자 동료로 등장합니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 질문 3: Julia는 누구인가요?\n",
    "print(\"=== 질문 3: Julia는 누구인가요? ===\")\n",
    "answer3 = chain.invoke(\"Julia는 누구인가요?\")\n",
    "print(answer3)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a68529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 대화 기록 ===\n",
      "[HumanMessage(content='Aaronson은 유죄인가요?'), AIMessage(content='System: 네, Jones, Aaronson 및 Rutherford는 자신들에게 적용된 범죄로 유죄 판결을 받았습니다.'), HumanMessage(content='그가 테이블에 어떤 메시지를 썼나요?'), AIMessage(content='System: 책에서 언급된 내용에는 Aaronson이 테이블에 어떤 메시지를 썼는지에 대한 구체적인 정보가 포함되어 있지 않습니다.'), HumanMessage(content='Julia는 누구인가요?'), AIMessage(content='System: Julia는 책에서 언급된 다른 주요 캐릭터 중 하나로, 윈스턴과 함께 이야기의 중심에 있는 여성입니다. 그녀는 윈스턴의 사랑이자 동료로 등장합니다.')]\n"
     ]
    }
   ],
   "source": [
    "# 메모리 상태 확인\n",
    "print(\"=== 대화 기록 ===\")\n",
    "print(memory.chat_memory.messages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
